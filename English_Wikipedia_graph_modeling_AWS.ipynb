{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Wikipedia clickstream data: the English Wiki in December 2018    \n",
    "\n",
    "## Graph modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Introduction  \n",
    "This notebook contains graph modeling steps for the English Wikipedia clickstream dataset for December 2018. It is a part of my project about the usage patterns of Wikipedia across language domains and over time.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Notebook setup  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import  csv\n",
    "\n",
    "from time import sleep\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "# custom general helper functions for this project\n",
    "import custom_utils as cu\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reload imports as needed\n",
    "importlib.reload(cu);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up Pandas options\n",
    "pd.set_option('display.max_columns', 25)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.precision', 3)\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get and check the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the cleaned tsv data onto AWS from my local machine\n",
    "# Run from terminal on local:\n",
    "# scp ~/projects/wiki_graph/data/clickstream-enwiki-2018-12_clean.tsv arinai@3.87.124.217:/home/arinai/data/\n",
    "# This took about 15 min.\n",
    "# Try getting the raw data with wget from Wikimedia datadump and then cleaning it next time to see if it's faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "other-empty\t2019_Horizon_League_Baseball_Tournament\texternal\t16\r\n",
      "other-search\tForeverAtLast\texternal\t40\r\n",
      "other-empty\tForeverAtLast\texternal\t85\r\n",
      "First_Families_of_Pakistan\tJehangir_Wadia\tlink\t19\r\n",
      "The_Lawrence_School,_Sanawar\tJehangir_Wadia\tlink\t36\r\n",
      "Wadia_family\tJehangir_Wadia\tlink\t715\r\n",
      "other-search\tJehangir_Wadia\texternal\t967\r\n",
      "Ness_Wadia\tJehangir_Wadia\tlink\t494\r\n",
      "other-empty\tJehangir_Wadia\texternal\t638\r\n",
      "GoAir\tJehangir_Wadia\tlink\t1191\r\n"
     ]
    }
   ],
   "source": [
    "# Print the head of the tsv file\n",
    "!head ../data/clickstream-enwiki-2018-12_clean.tsv\n",
    "\n",
    "# I move the file to neo4j's import folder later\n",
    "# !head /var/lib/neo4j/import/clickstream-enwiki-2018-12_clean.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read the cleaned up EN clickstream tsv file into pandas\n",
    "filepath = \"../data/clickstream-enwiki-2018-12_clean.tsv\"\n",
    "df = pd.read_csv(filepath, sep='\\t', names=['prev', 'curr', 'type', 'n'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace the false missing value NaNs with string \"NaN\"s\n",
    "df['prev'] = df['prev'].fillna('NaN')\n",
    "df['curr'] = df['curr'].fillna('NaN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "external_edges = df[df.type == \"external\"]\n",
    "internal_edges = df[df.type != \"external\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime: 0.04 min\n",
      "\n"
     ]
    }
   ],
   "source": [
    "st = timer()\n",
    "ext_nodes = set(external_edges[\"curr\"])\n",
    "\n",
    "cu.printRunTime(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5163109"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ext_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kakapo_(album)',\n",
       " \"When_You're_in_Love_with_a_Beautiful_Woman\",\n",
       " 'Th√©odore_Aubert',\n",
       " 'Instituto_de_Historia_de_Cuba',\n",
       " '2706',\n",
       " 'Renouf_Island',\n",
       " 'Ceyreste',\n",
       " 'Antoine_Omer_Talon',\n",
       " 'La_Possession_(film)',\n",
       " 'Priyanka_Bakaya']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ext_nodes)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def external_traffic(df, article, external_traffic_type):\n",
    "    traffic = df.loc[(df.curr == article) & (df.prev == external_traffic_type), 'n'].values\n",
    "    if len(traffic):\n",
    "        return traffic[0].item()\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ext_nodes_list = list(ext_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "external_traffic(external_edges, 'Renouf_Island', \"other-other\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Setting up Neo4j on AWS EC2 Ubuntu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install Neo4j community edition server  \n",
    "- For an Ubuntu EC2 instance on AWS, follow the Debian installation instructions [here](https://neo4j.com/docs/operations-manual/current/installation/linux/debian/). \n",
    "- [Run neo4j as a service using `systemctl`](https://neo4j.com/docs/operations-manual/current/installation/linux/systemd/#linux-service-control):  \n",
    "  - To start neo4j: `systemctl start neo4j`  \n",
    "  - To stop neo4j: `systemctl stop neo4j`\n",
    "\n",
    "- run neo4j and tunnel into the neo4j browser:\n",
    "  - run neo4j: `systemctl start neo4j`\n",
    "  - tunnel into the browser, e.g.: `ssh -NfL localhost:7474:localhost:7474 -L localhost:7687:localhost:7687 arinai@3.87.124.217`\n",
    "  - in a browser, open `http://localhost:7474/browser/`\n",
    "  - On first login, both the username and password are `neo4j`. After the initial login there will be a prompt to set a new password. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Load the data into Neo4j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from py2neo import authenticate, Graph, Node, Relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To avoid typing neo4j password into the notebook each time,\n",
    "# I'm saving it in a separate file and reading it in with the helper function below.\n",
    "def read_n4jpass():\n",
    "    \"\"\"Reads neo4j connection credentials from .n4jpass file in current folder.\n",
    "    Expects one value per line, ignores comments, e.g.:\n",
    "    # comments here\n",
    "    user=neo4j\n",
    "    password=secretStuff123\n",
    "    \"\"\"\n",
    "    \n",
    "    cur_folder = os.getcwd()\n",
    "    \n",
    "    with open(cur_folder + '/.n4jpass', 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    d = {}\n",
    "    for l in lines:\n",
    "        if l.strip() and (l[0] != '#'):\n",
    "            k, v = l.strip().split('=')\n",
    "            d[k] = v\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n4j_cred = read_n4jpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up authentication parameters\n",
    "authenticate(\"localhost:7474\", n4j_cred[\"user\"], n4j_cred[\"password\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# connect to authenticated graph database\n",
    "graph = Graph(\"http://localhost:7474/db/data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set indices  \n",
    "Unlike in relational databases, there are no built-in constraints or automatic indexing in neo4j. Since article names in Wikipedia should be unique, let's add a uniqueness constraint. This will make the import queries run faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graph.run(\"CREATE CONSTRAINT ON (a:Article) ASSERT a.title IS UNIQUE;\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>failureMessage</th>\n",
       "      <th>id</th>\n",
       "      <th>indexName</th>\n",
       "      <th>progress</th>\n",
       "      <th>properties</th>\n",
       "      <th>provider</th>\n",
       "      <th>state</th>\n",
       "      <th>tokenNames</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INDEX ON :Article(title)</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>index_1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>[title]</td>\n",
       "      <td>{'version': '1.0', 'key': 'native-btree'}</td>\n",
       "      <td>ONLINE</td>\n",
       "      <td>[Article]</td>\n",
       "      <td>node_unique_property</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                description failureMessage  id indexName  progress properties  \\\n",
       "0  INDEX ON :Article(title)                  1   index_1     100.0    [title]   \n",
       "\n",
       "                                    provider   state tokenNames  \\\n",
       "0  {'version': '1.0', 'key': 'native-btree'}  ONLINE  [Article]   \n",
       "\n",
       "                   type  \n",
       "0  node_unique_property  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list all indices in the db\n",
    "r = graph.data('CALL db.indexes;')\n",
    "pd.DataFrame(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read the data from ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prev</th>\n",
       "      <th>curr</th>\n",
       "      <th>type</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5383438</th>\n",
       "      <td>other-empty</td>\n",
       "      <td>Kakapo_(album)</td>\n",
       "      <td>external</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                prev            curr      type   n\n",
       "5383438  other-empty  Kakapo_(album)  external  13"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "external_edges[external_edges.curr == \"Kakapo_(album)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n",
      "1 2\n",
      "2 3\n"
     ]
    }
   ],
   "source": [
    "for counter, value in enumerate([1,2,3]):\n",
    "    print(counter, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0% done\n",
      "elapsed time: 0.07833123079999496 min\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-a4a8e2dddd52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Article\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marticle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"external_website_traffic\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexternal_traffic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexternal_edges\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marticle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"other-external\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"other_wikimedia_traffic\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexternal_traffic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexternal_edges\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marticle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"other-internal\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"external_search_traffic\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexternal_traffic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexternal_edges\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marticle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"other-search\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-43-cabf4d773b3f>\u001b[0m in \u001b[0;36mexternal_traffic\u001b[0;34m(df, article, external_traffic_type)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mexternal_traffic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marticle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexternal_traffic_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtraffic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurr\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0marticle\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprev\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mexternal_traffic_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'n'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraffic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtraffic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/arinai/anaconda3/lib/python3.5/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other, axis)\u001b[0m\n\u001b[1;32m    761\u001b[0m                 \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mna_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    764\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m                 raise TypeError('Could not compare %s type with Series' %\n",
      "\u001b[0;32m/home/arinai/anaconda3/lib/python3.5/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mna_op\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    681\u001b[0m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvec_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    684\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = timer()\n",
    "\n",
    "ext_nodes_count = len(ext_nodes_list)\n",
    "\n",
    "last_i = 0\n",
    "\n",
    "for i, article in enumerate(ext_nodes_list):\n",
    "    tx = graph.begin()\n",
    "\n",
    "    a = Node(\"Article\", title=article)\n",
    "    a[\"external_website_traffic\"] = external_traffic(external_edges, article, \"other-external\")\n",
    "    a[\"other_wikimedia_traffic\"] = external_traffic(external_edges, article, \"other-internal\")\n",
    "    a[\"external_search_traffic\"] = external_traffic(external_edges, article, \"other-search\")\n",
    "    a[\"empty_referer_traffic\"] = external_traffic(external_edges, article, \"other-empty\")\n",
    "    a[\"unknown_external_traffic\"] = external_traffic(external_edges, article, \"other-other\")\n",
    "    \n",
    "    tx.create(a)\n",
    "    tx.commit()\n",
    "    \n",
    "    last_i = i\n",
    "    \n",
    "    if i % 1000000 == 0:\n",
    "        print(str(round(i/ext_nodes_count * 100)) +'% done')\n",
    "        print(\"elapsed time:\", (timer() - start_time)/60, \"min\\n\")\n",
    "        \n",
    "\n",
    "cu.printRunTime(start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "289"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = Node(\"Person\", name=\"Alice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(alice:Person {name:\"Alice\"})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test[\"age\"] = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(alice:Person {age:20,name:\"Alice\"})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['wt'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(alice:Person {age:20,name:\"Alice\"})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "tx = graph.begin()\n",
    ">>> a = Node(\"Person\", name=\"Alice\")\n",
    ">>> tx.create(a)\n",
    ">>> b = Node(\"Person\", name=\"Bob\")\n",
    ">>> ab = Relationship(a, \"KNOWS\", b)\n",
    ">>> tx.create(ab)\n",
    ">>> tx.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_time = timer()\n",
    "with open(\"../data/external_nodes.tsv\",\"w\") as tsvfile:\n",
    "    wr = csv.writer(tsvfile, delimiter='\\t')\n",
    "    \n",
    "    # header\n",
    "    wr.writerow([\"title\", \n",
    "                 \"external_website_traffic\", \n",
    "                 \"other_wikimedia_traffic\", \n",
    "                 \"external_search_traffic\", \n",
    "                 \"empty_referer_traffic\", \n",
    "                 \"unknown_external_traffic\"])\n",
    "    #rows\n",
    "    for article in ext_nodes_list:\n",
    "        wr.writerow([article, \n",
    "                     external_traffic(external_edges, article, \"other-external\"), \n",
    "                     external_traffic(external_edges, article, \"other-internal\"), \n",
    "                     external_traffic(external_edges, article, \"other-search\"), \n",
    "                     external_traffic(external_edges, article, \"other-empty\"), \n",
    "                     external_traffic(external_edges, article, \"other-other\")])\n",
    "        \n",
    "\n",
    "cu.printRunTime(start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "tx = graph.begin()\n",
    ">>> a = Node(\"Person\", name=\"Alice\")\n",
    ">>> tx.create(a)\n",
    ">>> b = Node(\"Person\", name=\"Bob\")\n",
    ">>> ab = Relationship(a, \"KNOWS\", b)\n",
    ">>> tx.create(ab)\n",
    ">>> tx.commit()\n",
    ">>> graph.exists(ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph.exists(ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, neo4j only imports data from its own `import` subfolder (on Ubuntu, it is `/var/lib/neo4j/import`) or from an url, so make sure to move the data into the neo4j import folder (alternatively, this requirement can be commented out in the `conf` file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = \"clickstream-enwiki-2018-12_clean.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[other-empty, 2019_Horizon_League_Baseball_Tou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[other-search, ForeverAtLast, external, 40]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[other-empty, ForeverAtLast, external, 85]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[First_Families_of_Pakistan, Jehangir_Wadia, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[The_Lawrence_School,_Sanawar, Jehangir_Wadia,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[Wadia_family, Jehangir_Wadia, link, 715]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[other-search, Jehangir_Wadia, external, 967]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[Ness_Wadia, Jehangir_Wadia, link, 494]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[other-empty, Jehangir_Wadia, external, 638]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[GoAir, Jehangir_Wadia, link, 1191]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 row\n",
       "0  [other-empty, 2019_Horizon_League_Baseball_Tou...\n",
       "1        [other-search, ForeverAtLast, external, 40]\n",
       "2         [other-empty, ForeverAtLast, external, 85]\n",
       "3  [First_Families_of_Pakistan, Jehangir_Wadia, l...\n",
       "4  [The_Lawrence_School,_Sanawar, Jehangir_Wadia,...\n",
       "5          [Wadia_family, Jehangir_Wadia, link, 715]\n",
       "6      [other-search, Jehangir_Wadia, external, 967]\n",
       "7            [Ness_Wadia, Jehangir_Wadia, link, 494]\n",
       "8       [other-empty, Jehangir_Wadia, external, 638]\n",
       "9                [GoAir, Jehangir_Wadia, link, 1191]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = 'file:///' + filename\n",
    "    \n",
    "query_test = \"\"\"\n",
    "    LOAD CSV FROM {myfilepath} AS row\n",
    "    FIELDTERMINATOR '\\t'\n",
    "    return row\n",
    "    limit 10\n",
    "    ;\n",
    "    \"\"\"\n",
    "\n",
    "test = graph.data(query_test, myfilepath=str(fp))\n",
    "pd.DataFrame(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row[0]</th>\n",
       "      <th>row[1]</th>\n",
       "      <th>split(row[0], '-')[1]</th>\n",
       "      <th>toInteger(row[3])</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>other-empty</td>\n",
       "      <td>2019_Horizon_League_Baseball_Tournament</td>\n",
       "      <td>empty</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>other-search</td>\n",
       "      <td>ForeverAtLast</td>\n",
       "      <td>search</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>other-empty</td>\n",
       "      <td>ForeverAtLast</td>\n",
       "      <td>empty</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>First_Families_of_Pakistan</td>\n",
       "      <td>Jehangir_Wadia</td>\n",
       "      <td>None</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The_Lawrence_School,_Sanawar</td>\n",
       "      <td>Jehangir_Wadia</td>\n",
       "      <td>None</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wadia_family</td>\n",
       "      <td>Jehangir_Wadia</td>\n",
       "      <td>None</td>\n",
       "      <td>715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>other-search</td>\n",
       "      <td>Jehangir_Wadia</td>\n",
       "      <td>search</td>\n",
       "      <td>967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ness_Wadia</td>\n",
       "      <td>Jehangir_Wadia</td>\n",
       "      <td>None</td>\n",
       "      <td>494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>other-empty</td>\n",
       "      <td>Jehangir_Wadia</td>\n",
       "      <td>empty</td>\n",
       "      <td>638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GoAir</td>\n",
       "      <td>Jehangir_Wadia</td>\n",
       "      <td>None</td>\n",
       "      <td>1191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         row[0]                                   row[1]  \\\n",
       "0                   other-empty  2019_Horizon_League_Baseball_Tournament   \n",
       "1                  other-search                            ForeverAtLast   \n",
       "2                   other-empty                            ForeverAtLast   \n",
       "3    First_Families_of_Pakistan                           Jehangir_Wadia   \n",
       "4  The_Lawrence_School,_Sanawar                           Jehangir_Wadia   \n",
       "5                  Wadia_family                           Jehangir_Wadia   \n",
       "6                  other-search                           Jehangir_Wadia   \n",
       "7                    Ness_Wadia                           Jehangir_Wadia   \n",
       "8                   other-empty                           Jehangir_Wadia   \n",
       "9                         GoAir                           Jehangir_Wadia   \n",
       "\n",
       "  split(row[0], '-')[1]  toInteger(row[3])  \n",
       "0                 empty                 16  \n",
       "1                search                 40  \n",
       "2                 empty                 85  \n",
       "3                  None                 19  \n",
       "4                  None                 36  \n",
       "5                  None                715  \n",
       "6                search                967  \n",
       "7                  None                494  \n",
       "8                 empty                638  \n",
       "9                  None               1191  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_test = \"\"\"\n",
    "    LOAD CSV FROM {myfilepath} AS row\n",
    "    FIELDTERMINATOR '\\t'\n",
    "    return row[0], row[1], split(row[0], '-')[1], toInteger(row[3])\n",
    "    limit 10\n",
    "    ;\n",
    "    \"\"\"\n",
    "\n",
    "test = graph.data(query_test, myfilepath=str(fp))\n",
    "pd.DataFrame(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cypher-shell queries\n",
    "\n",
    "###############\n",
    "### NODES  ####\n",
    "###############\n",
    "\n",
    "### External reference type #################################################\n",
    "\n",
    "USING PERIODIC COMMIT\n",
    "    LOAD CSV FROM \"file:///clickstream-enwiki-2018-12_clean.tsv\" AS row\n",
    "    FIELDTERMINATOR '\\t'\n",
    "    WITH row\n",
    "    WHERE row[0] = 'other-empty' \n",
    "    CREATE (n:Article { title: row[1], empty_referer_traffic:  toInteger(row[3]) })\n",
    "    ;\n",
    "# the above ran for about 5 min in terminal cypher-shell on AWS\n",
    "# Added 5093433 nodes, Set 10186866 properties, Added 5093433 labels\n",
    "\n",
    "\n",
    "USING PERIODIC COMMIT\n",
    "    LOAD CSV FROM \"file:///clickstream-enwiki-2018-12_clean.tsv\" AS row\n",
    "    FIELDTERMINATOR '\\t'\n",
    "    WITH row\n",
    "    WHERE row[0] = 'other-external' \n",
    "    MERGE (n:Article { title: row[1] })\n",
    "    ON CREATE SET n.external_website_traffic = toInteger(row[3])\n",
    "    ON MATCH SET n.external_website_traffic = toInteger(row[3])\n",
    "    ;\n",
    "# the above ran for about 2 min in terminal cypher-shell on AWS\n",
    "# Added 726 nodes, Set 788037 properties, Added 726 labels\n",
    "\n",
    "\n",
    "USING PERIODIC COMMIT\n",
    "    LOAD CSV FROM \"file:///clickstream-enwiki-2018-12_clean.tsv\" AS row\n",
    "    FIELDTERMINATOR '\\t'\n",
    "    WITH row\n",
    "    WHERE row[0] = 'other-other' \n",
    "    MERGE (n:Article { title: row[1] })\n",
    "    ON CREATE SET n.unknown_external_traffic = toInteger(row[3])\n",
    "    ON MATCH SET n.unknown_external_traffic = toInteger(row[3])\n",
    "    ;\n",
    "# the above ran for about 2 min in terminal cypher-shell on AWS\n",
    "# Added 31 nodes, Set 374952 properties, Added 31 labels\n",
    "\n",
    "\n",
    "USING PERIODIC COMMIT\n",
    "    LOAD CSV FROM \"file:///clickstream-enwiki-2018-12_clean.tsv\" AS row\n",
    "    FIELDTERMINATOR '\\t'\n",
    "    WITH row\n",
    "    WHERE row[0] = 'other-internal' \n",
    "    MERGE (n:Article { title: row[1] })\n",
    "    ON CREATE SET n.other_wikimedia_traffic = toInteger(row[3])\n",
    "    ON MATCH SET n.other_wikimedia_traffic = toInteger(row[3])\n",
    "    ;\n",
    "# the above ran for about 2 min in terminal cypher-shell on AWS\n",
    "# Added 3454 nodes, Set 1352346 properties, Added 3454 labels\n",
    "\n",
    "\n",
    "USING PERIODIC COMMIT\n",
    "    LOAD CSV FROM \"file:///clickstream-enwiki-2018-12_clean.tsv\" AS row\n",
    "    FIELDTERMINATOR '\\t'\n",
    "    WITH row\n",
    "    WHERE row[0] = 'other-search' \n",
    "    MERGE (n:Article { title: row[1] })\n",
    "    ON CREATE SET n.external_search_traffic = toInteger(row[3])\n",
    "    ON MATCH SET n.external_search_traffic = toInteger(row[3])\n",
    "    ;\n",
    "# the above ran for about 3.5 min in terminal cypher-shell on AWS\n",
    "# Added 65465 nodes, Set 3451890 properties, Added 65465 labels\n",
    "\n",
    "\n",
    "\n",
    "### Non-external reference type #################################################\n",
    "\n",
    "USING PERIODIC COMMIT\n",
    "    LOAD CSV FROM \"file:///clickstream-enwiki-2018-12_clean.tsv\" AS row\n",
    "    FIELDTERMINATOR '\\t'\n",
    "    WITH row\n",
    "    WHERE row[2] <> 'external' \n",
    "    MERGE (n1:Article { title: row[0] })\n",
    "    MERGE (n2:Article { title: row[1] })\n",
    "    ;\n",
    "# the above ran for about 13 min in terminal cypher-shell on AWS\n",
    "# Added 22590 nodes, Set 22590 properties, Added 22590 labels\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###############\n",
    "### EGDES  ####\n",
    "###############\n",
    "\n",
    "\n",
    "### LINK_TO relationships #################################################\n",
    "USING PERIODIC COMMIT\n",
    "    LOAD CSV FROM \"file:///clickstream-enwiki-2018-12_clean.tsv\" AS row\n",
    "    FIELDTERMINATOR '\\t'\n",
    "    WITH row\n",
    "    WHERE row[2] = 'link' \n",
    "    MATCH (n1:Article { title: row[0] })\n",
    "    MATCH (n2:Article { title: row[1] })\n",
    "    CREATE (n1)-[r:LINK_TO { traffic: toInteger(row[3]) }]->(n2)\n",
    "    ;\n",
    "# the above ran for about 26 min in terminal cypher-shell on AWS\n",
    "# Created 17851574 relationships, Set 17851574 properties\n",
    "\n",
    "\n",
    "### SEARCH_FOR relationships ##############################################\n",
    "USING PERIODIC COMMIT\n",
    "    LOAD CSV FROM \"file:///clickstream-enwiki-2018-12_clean.tsv\" AS row\n",
    "    FIELDTERMINATOR '\\t'\n",
    "    WITH row\n",
    "    WHERE row[2] = 'other' \n",
    "    MATCH (n1:Article { title: row[0] })\n",
    "    MATCH (n2:Article { title: row[1] })\n",
    "    CREATE (n1)-[r:SEARCH_FOR { traffic: toInteger(row[3]) }]->(n2)\n",
    "    ;\n",
    "\n",
    "# the above ran for about 14 min in terminal cypher-shell on AWS\n",
    "# Created 1005180 relationships, Set 1005180 properties\n",
    "\n",
    "\n",
    "# Total runtime is about 70 min on AWS cypher-shell. Every other method of import was much much slower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Cypher queries for inspecting data in the neo4j browser (screenshots saved on desktop for now)\n",
    "\n",
    "# visualize db schema (`call db.schema()` has been depreciated)\n",
    "call db.schema.visualization()\n",
    "\n",
    "\n",
    "# looking into Main_Page single-hop graphs\n",
    "# Main_Page out links\n",
    "match p=(a:Article)-[r:LINK_TO]->()\n",
    "where a.title=\"Main_Page\"\n",
    "return p\n",
    "limit 200\n",
    "\n",
    "# Main_Page in links\n",
    "match p=(a:Article)<-[r:LINK_TO]-()\n",
    "where a.title=\"Main_Page\"\n",
    "return p\n",
    "limit 200\n",
    "\n",
    "\n",
    "# Main_Page out searches\n",
    "match p=(a:Article)-[r:SEARCH_FOR]->()\n",
    "where a.title=\"Main_Page\"\n",
    "return p\n",
    "limit 200\n",
    "\n",
    "# Main_Page in searches\n",
    "match p=(a:Article)<-[r:SEARCH_FOR]-()\n",
    "where a.title=\"Main_Page\"\n",
    "return p\n",
    "limit 200\n",
    "\n",
    "\n",
    "# Conclusion:\n",
    "# Keep link traffic to Main_Page, but drop link traffic from Main_Page and to/from search traffic, \n",
    "# save the dropped Main_Page traffic values on nodes.\n",
    "\n",
    "# cypher-shell query to remove Main_Page out-link-traffic\n",
    "MATCH (mp:Article {title: \"Main_Page\"})-[r:LINK_TO]->(a:Article)\n",
    "SET a.link_traffic_from_main_page = r.traffic\n",
    "DELETE r;\n",
    "# 0 rows available after 141 ms, consumed after another 0 ms\n",
    "# Deleted 73 relationships, Set 73 properties\n",
    "\n",
    "# cypher-shell query to remove Main_Page out-search-traffic\n",
    "MATCH (mp:Article {title: \"Main_Page\"})-[r:SEARCH_FOR]->(a:Article)\n",
    "SET a.search_traffic_from_main_page = r.traffic\n",
    "DELETE r;\n",
    "# 0 rows available after 30816 ms, consumed after another 0 ms\n",
    "# Deleted 257794 relationships, Set 257794 properties\n",
    "\n",
    "# cypher-shell query to remove Main_Page in-search-traffic\n",
    "MATCH (mp:Article {title: \"Main_Page\"})<-[r:SEARCH_FOR]-(a:Article)\n",
    "SET a.search_traffic_to_main_page = r.traffic\n",
    "DELETE r;\n",
    "# 0 rows available after 1427 ms, consumed after another 0 ms\n",
    "# Deleted 110009 relationships, Set 110009 properties\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# looking into Hyphen-minus single-hop search subgraphs\n",
    "\n",
    "# out searches\n",
    "match p=(a:Article)-[r:SEARCH_FOR]->()\n",
    "where a.title=\"Hyphen-minus\"\n",
    "return p\n",
    "limit 200\n",
    "# The only out-search from \"Hyphen-minus\" was to Main_Page, which was deleted in the queries above\n",
    "\n",
    "# in searches\n",
    "match p=(a:Article)<-[r:SEARCH_FOR]-()\n",
    "where a.title=\"Hyphen-minus\"\n",
    "return p\n",
    "limit 200\n",
    "\n",
    "\n",
    "# Conclusion:\n",
    "# Drop in-search traffic to \"Hyphen-minus\", \n",
    "# don't really need to save the dropped \"Hyphen-minus\" traffic values on nodes,\n",
    "# but doing it just in case it looks interesting later.\n",
    "\n",
    "# cypher-shell query to remove \"Hyphen-minus\" in-search-traffic\n",
    "MATCH (hm:Article {title: \"Hyphen-minus\"})<-[r:SEARCH_FOR]-(a:Article)\n",
    "SET a.search_traffic_to_hyphen_minus = r.traffic\n",
    "DELETE r;\n",
    "# 0 rows available after 1569 ms, consumed after another 0 ms\n",
    "# Deleted 127457 relationships, Set 127457 properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# looking into Undefined single-hop search subgraphs\n",
    "\n",
    "# out searches\n",
    "match p=(a:Article)-[r:SEARCH_FOR]->()\n",
    "where a.title=\"Undefined\"\n",
    "return p\n",
    "limit 200\n",
    "# The only out-search from \"Undefined\" was to Main_Page, which was deleted in the queries above\n",
    "\n",
    "# in searches\n",
    "match p=(a:Article)<-[r:SEARCH_FOR]-()\n",
    "where a.title=\"Undefined\"\n",
    "return p\n",
    "limit 200\n",
    "\n",
    "\n",
    "# Conclusion:\n",
    "# Drop in-search traffic to \"Undefined\", \n",
    "# don't really need to save the dropped \"Undefined\" traffic values on nodes,\n",
    "# but doing it just in case it looks interesting later.\n",
    "\n",
    "# cypher-shell query to remove \"Undefined\" in-search-traffic\n",
    "MATCH (u:Article {title: \"Undefined\"})<-[r:SEARCH_FOR]-(a:Article)\n",
    "SET a.search_traffic_to_undefined = r.traffic\n",
    "DELETE r;\n",
    "# 0 rows available after 37 ms, consumed after another 0 ms\n",
    "# Deleted 241 relationships, Set 241 properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sample final graph paths in neo4j browser\n",
    "MATCH p=()-[]->() RETURN p LIMIT 300\n",
    "\n",
    "# looks good, we're done with graph modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
